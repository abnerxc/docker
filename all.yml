version: '3'
networks:
  mynet:  #这里可以自定义名称 ，跟引用的地方一致就行
    driver: bridge
    ipam:
      config:
        - subnet: 172.18.0.0/24

volumes:
  mongodb_data:
    driver: local

services:
  nginx:
    image: nginx:alpine
    ports:
      - 80:80
      - 443:443
    volumes:
      - ./www/:/var/www/html/:rw
      - ./conf/nginx/conf.d:/etc/nginx/conf.d/:rw
      - ./conf/nginx/nginx.conf:/etc/nginx/nginx.conf:rw
      - ./log/nginx/:/var/log/nginx/:rw
    container_name: nginx
    privileged: true #解决不可以写宿主机目录权限问题，如果是centos7也可以关闭selinux
    environment:
      - TZ=Asia/Shanghai
    extra_hosts:
      - "ticket-dev.icsoc.net:127.0.0.1"  #容器绑定host
    networks:
      mynet:
        ipv4_address: 172.18.0.50

  redis:
    image: redis:alpine
    container_name: redis
    privileged: true
    ports:
      - "6379:6379"
    command: redis-server --requirepass 123456
    networks:
      mynet:
        ipv4_address: 172.18.0.100
    deploy: #容器限制资源用法
      resources:
        limits:
          cpus: '0.50'
          memory: 10M

  memcached:
    image: memcached:alpine
    container_name: memcached
    privileged: true
    ports:
      - "11211:11211"
    networks:
      mynet:
        ipv4_address: 172.18.0.101

  mysql:
    image: mysql:5.6.45
    container_name: mysql
    privileged: true
    ports:
      - "3306:3306"
    volumes:
      - ./conf/mysql/my.cnf:/etc/mysql/my.cnf
#      - ./data/mysql/:/var/lib/mysql/
      - ./data/mysql/:/usr/data/ #5.6.45
      - ./log/mysql/:/var/log/mysql/
    command: --innodb-flush-method=O_DSYNC --innodb-use-native-aio=0 --log_bin=ON #解决windows挂载无法启动
    environment:
       MYSQL_ROOT_PASSWORD: 123456
    networks:
      mynet:
        ipv4_address: 172.18.0.102

  mongodb:
    image: mongo
    container_name: mongodb
    privileged: true
    ports:
      - "27017:27017"
    volumes:   #win10 -v 方法挂载目前无解
      - mongodb_data:/data/db/
    command: --auth --bind_ip_all
    environment:
      MONGO_INITDB_ROOT_USERNAME: root
      MONGO_INITDB_ROOT_PASSWORD: 123456
    networks:
      mynet:
        ipv4_address: 172.18.0.103

  kibana:
    image: kibana:5.6.12
    container_name: kibana
    privileged: true
    environment:
      - ELASTICSEARCH_URL=http://172.18.0.104:9200
    ports:
      - 5601:5601
    networks:
      std:
        ipv4_address: 172.18.0.106

  php82:
    image: registry.cn-guangzhou.aliyuncs.com/xuchen/php:8.2
    expose:
      - 9000
    volumes:
      - ./www/:/var/www/html/:rw
      - ./conf/php/php.ini:/usr/local/etc/php/php.ini
      - ./conf/php/php-fpm.d/www.conf:/usr/local/etc/php-fpm.d/www.conf
      - ./log/php-fpm/:/var/log/php-fpm/
    container_name: php82
    privileged: true
    extra_hosts:
      - "hddev.kerlala.com:172.18.0.50"
      - "jxjkhddev.kerlala.com:172.18.0.50"
      - "jxjkhdcrmdev.kerlala.com:172.18.0.50"
      - "mockdev.kerlala.com:172.18.0.50"
      - "casdev.kerlala.com:172.18.0.50"
    networks:
      jhm:
        ipv4_address: 172.18.0.82

  vuecli:
   image: registry.cn-guangzhou.aliyuncs.com/xuchen/node:1.0
   tty: true
   ports:
     - '8081:8081'
     - '4000:4000'
   volumes:
     - '/Users/abner/work/gopro/govue/front:/app/front'
     - '/Users/abner/work/blog:/app/blog'
     - '/Users/abner/.ssh:/root/.ssh'
   container_name: vuecli #node-dev
   networks:
     jhm:
       ipv4_address: 172.18.0.10

  elasticsearch:
    image: elasticsearch
    container_name: es
    privileged: true
    ports:
      - "9200:9200"
      - "9300:9300"
    environment:
      - http.port=9200
      - discovery.type=single-node
    networks:
      mynet:
        ipv4_address: 172.18.0.40

  rabbitmq:
    image: rabbitmq:3.7.15-management-alpine
    container_name: rabbitmq
    privileged: true
    volumes:
      - ./data/rabbitmq/:/var/lib/rabbitmq #数据存储目录
      - ./log/rabbitmq/:/var/log/rabbitmq #日志目录
    environment:
      RABBITMQ_DEFAULT_USER: admin
      RABBITMQ_DEFAULT_PASS: admin
      RABBITMQ_DEFAULT_VHOST: 'vhost'
    ports:
      - "15672:15672"
      - "5672:5672"
    logging:
      driver: "json-file"
      options:
        max-size: "200k"
        max-file: "10"
    networks:
      mynet:
        ipv4_address: 172.18.0.50

  etcd-node1:
    image: quay.io/coreos/etcd:v3.3.1
    container_name: etcd-node1
    ports:
      - "12379:2379"
      - "12380:2380"
    restart: always
    volumes:
      - ./data/etcd/node1:/data/app/etcd
    command: etcd --name etcd-node1 --data-dir /data/app/etcd/ --advertise-client-urls http://172.18.0.60:2379 --initial-advertise-peer-urls http://172.18.0.60:2380 --listen-client-urls http://0.0.0.0:2379 --listen-peer-urls http://0.0.0.0:2380 --initial-cluster-token etcd-cluster --initial-cluster "etcd-node1=http://172.18.0.60:2380,etcd-node2=http://172.18.0.61:2380,etcd-node3=http://172.18.0.62:2380" --initial-cluster-state new
    networks:
      mynet:
        ipv4_address: 172.18.0.60

  etcd-node2:
    image: quay.io/coreos/etcd:v3.3.1
    container_name: etcd-node2
    ports:
      - "22379:2379"
      - "22380:2380"
    restart: always
    volumes:
      - ./data/etcd/node2:/data/app/etcd
    command: etcd --name etcd-node2 --data-dir /data/app/etcd/ --advertise-client-urls http://172.18.0.61:2379 --initial-advertise-peer-urls http://172.18.0.61:2380 --listen-client-urls http://0.0.0.0:2379 --listen-peer-urls http://0.0.0.0:2380 --initial-cluster-token etcd-cluster --initial-cluster "etcd-node1=http://172.18.0.60:2380,etcd-node2=http://172.18.0.61:2380,etcd-node3=http://172.18.0.62:2380" --initial-cluster-state new
    networks:
      mynet:
        ipv4_address: 172.18.0.61

  etcd-node3:
    image: quay.io/coreos/etcd:v3.3.1
    container_name: etcd-node3
    ports:
      - "32379:2379"
      - "32380:2380"
    restart: always
    volumes:
      - ./data/etcd/node3:/data/app/etcd
    command: etcd --name etcd-node3 --data-dir /data/app/etcd/ --advertise-client-urls http://172.18.0.62:2379 --initial-advertise-peer-urls http://172.18.0.62:2380 --listen-client-urls http://0.0.0.0:2379 --listen-peer-urls http://0.0.0.0:2380 --initial-cluster-token etcd-cluster --initial-cluster "etcd-node1=http://172.18.0.60:2380,etcd-node2=http://172.18.0.61:2380,etcd-node3=http://172.18.0.62:2380" --initial-cluster-state new
    networks:
      mynet:
        ipv4_address: 172.18.0.62

  zookeeper:
    image: wurstmeister/zookeeper
    container_name: zookeeper
    ports:
      - "2181:2181"
    networks:
      mynet:
        ipv4_address: 172.18.0.120

  kafka2:
    image: wurstmeister/kafka
    container_name: kafka2
    depends_on:
      - zookeeper
    ports:
      - "9092:9092"
    environment:
      KAFKA_BROKER_ID: 2
      KAFKA_ZOOKEEPER_CONNECT: 172.18.0.120:2181 #zookeeper服务地址 docker restart kafka2 kafka3 kafka4
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://172.18.0.122:9092 #kafka服务地址,ip和端口号要写对
      KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:9092
      KAFKA_LOG_DIRS: /data/kafka-data
    volumes:
      - ./data/kafka/kafka2:/data/kafka-data
    networks:
      mynet:
        ipv4_address: 172.18.0.122

  kafka3:
    image: wurstmeister/kafka
    container_name: kafka3
    depends_on:
      - zookeeper
    ports:
      - "9093:9093"
    environment:
      KAFKA_BROKER_ID: 3
      KAFKA_ZOOKEEPER_CONNECT: 172.18.0.120:2181 #zookeeper服务地址
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://172.18.0.123:9093 #kafka服务地址
      KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:9093
      KAFKA_LOG_DIRS: /data/kafka-data
    volumes:
      - ./data/kafka/kafka3:/data/kafka-data
    networks:
      mynet:
        ipv4_address: 172.18.0.123

  kafka4:
    image: wurstmeister/kafka
    container_name: kafka4
    depends_on:
      - zookeeper
    ports:
      - "9094:9094"
    environment:
      KAFKA_BROKER_ID: 4
      KAFKA_ZOOKEEPER_CONNECT: 172.18.0.120:2181 #zookeeper服务地址
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://172.18.0.124:9094 #kafka服务地址
      KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:9094
      KAFKA_LOG_DIRS: /data/kafka-data
    volumes:
      - ./data/kafka/kafka4:/data/kafka-data
    networks:
      mynet:
        ipv4_address: 172.18.0.124